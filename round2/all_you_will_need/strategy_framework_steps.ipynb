{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Appropriate Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import random\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import talib as ta\n",
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, hp, partial, tpe, Trials\n",
    "\n",
    "#silence warnings output...\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#following for the ML part...setting a seed meant that multiple executions will yield the same result.\n",
    "random_state = 42\n",
    "random.seed(random_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths and Load CSV (Modify Path Here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of df_market are: ['date_time', 'open', 'close', 'high', 'low', 'volume', 'money']\n",
      "Columns of df_fund are: ['date_time', 'turnoverRatio', 'transactionAmount', 'pe_ttm', 'pe', 'pb', 'ps', 'pcf']\n",
      "Columns of df_return are: ['date_time', 'return']\n"
     ]
    }
   ],
   "source": [
    "historical_data_path = '''second_round_datasets'''\n",
    "MARKET_DATA_PATH = f'{historical_data_path}/second_round_train_market_data.csv'\n",
    "FUNDAMENTAL_DATA_PATH = f'{historical_data_path}/second_round_train_fundamental_data.csv'\n",
    "RETURN_DATA_PATH = f'{historical_data_path}/second_round_train_return_data.csv'\n",
    "\n",
    "df_market = pd.read_csv(MARKET_DATA_PATH)\n",
    "df_fund = pd.read_csv(FUNDAMENTAL_DATA_PATH)\n",
    "df_return = pd.read_csv(RETURN_DATA_PATH)\n",
    "print(f\"Columns of df_market are: {list(df_market.columns)}\")\n",
    "print(f\"Columns of df_fund are: {list(df_fund.columns)}\")\n",
    "print(f\"Columns of df_return are: {list(df_return.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran\n"
     ]
    }
   ],
   "source": [
    "#To Create columns containing data column of \"date_time\"\n",
    "def interval_split(dt):\n",
    "    #for date_time column of \"sXXdXXpXX\"\n",
    "    f2, f3 = dt.find(\"d\"), dt.find(\"p\")\n",
    "    return [int(dt[1:f2]), int(dt[f2+1:f3]), int(dt[f3+1:])]\n",
    "def date_split(dt):\n",
    "    #for date_time column of \"sXXdXX\"\n",
    "    f2 = dt.find(\"d\")\n",
    "    return [int(dt[1:f2]), int(dt[f2+1:])]\n",
    "def add_interval(df):\n",
    "    df_interval_data = np.vstack(df.date_time.apply(lambda x: interval_split(x)))\n",
    "    df[[\"asset\", \"day\", \"interval\"]] = df_interval_data\n",
    "    return df\n",
    "def add_date(df):\n",
    "    df_date_data = np.vstack(df.date_time.apply(lambda x: date_split(x)))\n",
    "    df[[\"asset\", \"day\"]] = df_date_data\n",
    "    return df\n",
    "print(\"Ran\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_period(df):\n",
    "    #no intervals\n",
    "    df_period = df[['asset', 'day']]\n",
    "    for i in range(2, 15):\n",
    "        df_period[f\"period{i}\"] = df[\"day\"] // i\n",
    "    return df_period\n",
    "def add_remainder(df):\n",
    "    #no intervals\n",
    "    df_remainder = df[['asset', 'day']]\n",
    "    for i in range(2, 15):\n",
    "        df_remainder[f\"remainder{i}\"] = df[\"day\"] % i\n",
    "    return df_remainder\n",
    "\n",
    "def ctc_returns(df_market_a):\n",
    "    #no intervals\n",
    "    df_ctc = df_market_a[['asset', 'day']].reset_index(drop=True)\n",
    "    for days in [1, 5, 10, 20]:\n",
    "        df_ctc[f\"ctc{days}\"] = df_market_a['close'].pct_change(days).reset_index(drop=True)\n",
    "    return df_ctc\n",
    "\n",
    "\n",
    "def daily_volume_moving_ratio(df_market_a):\n",
    "    #contains intervals\n",
    "    #take df by asset type\n",
    "    daily_volume_series = df_market_a.groupby(df_market_a['day'])['volume'].sum()\n",
    "    df_movv = df_market_a[['asset', 'day']].drop_duplicates(subset=[\"asset\", \"day\"], keep='last').reset_index(drop=True)\n",
    "    df_movv[\"daily_volume_moving_ratio_5d\"] = daily_volume_series / daily_volume_series.rolling(5).mean()\n",
    "    df_movv[\"daily_volume_moving_ratio_10d\"] = daily_volume_series / daily_volume_series.rolling(10).mean()\n",
    "    df_movv[\"daily_volume_moving_ratio_20d\"] = daily_volume_series / daily_volume_series.rolling(20).mean()\n",
    "    return df_movv\n",
    "\n",
    "\n",
    "#Talib Features **\n",
    "def add_talib_features(df_market_a):\n",
    "    #This function take reference to the \"construct_talib_features\" function and tailor to our dataframe settings\n",
    "    #by creating asset, day, interval columns (prior), following code should be more understandable\n",
    "    close_p = df_market_a[df_market_a['interval'] == 50]['close'].reset_index(drop=True)\n",
    "    high_p = df_market_a.groupby(df_market_a['day'])['high'].max().reset_index(drop=True)\n",
    "    low_p = df_market_a.groupby(df_market_a['day'])['low'].min().reset_index(drop=True)\n",
    "\n",
    "    feature_df = df_market_a[['asset', 'day']].drop_duplicates(subset=[\"asset\", \"day\"], keep='last').reset_index(drop=True)\n",
    "    feature_df[\"SAR\"] = ta.SAR(high_p, low_p, acceleration = 0, maximum = 0)\n",
    "    feature_df[\"SAREXT\"] = ta.SAREXT(high_p, low_p, startvalue = 0, offsetonreverse = 0, accelerationinitlong = 0, accelerationlong = 0, accelerationmaxlong = 0, accelerationinitshort = 0, accelerationshort = 0, accelerationmaxshort = 0)\n",
    "    feature_df[\"RSI\"] = ta.RSI(close_p, timeperiod = 14) - 50\n",
    "    feature_df[\"HT_DCPERIOD\"] = ta.HT_DCPERIOD(close_p)\n",
    "    feature_df[\"HT_PHASOR_inphase\"], feature_df[\"HT_PHASOR_quadrature\"] = ta.HT_PHASOR(close_p)\n",
    "    feature_df[\"HT_SINE_sine\"], feature_df[\"HT_SINE_leadsine\"] = ta.HT_SINE(close_p)\n",
    "    return feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features in Consideration\n",
    "def merge_columns(market, fundamental, returns=pd.DataFrame([0])):\n",
    "    market = add_interval(market)\n",
    "    fundamental = add_date(fundamental)\n",
    "    df = pd.merge(market, fundamental, left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "    if returns.any()[0]:    #check if returns is a non-empty dataframe\n",
    "        returns = add_date(returns)\n",
    "        df = pd.merge(df, returns, left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "    # Note: This Step Will Mean that Metrics regarding\n",
    "    return df\n",
    "    # df = df.drop_duplicates(subset=[\"asset\", \"day\"], keep='last').reset_index(drop=True)\n",
    "\n",
    "def add_features(df):\n",
    "    #THIS will return columns with only one set of ['asset', 'day'] (no intervals)\n",
    "    df_close_only = df.drop_duplicates(subset=[\"asset\", \"day\"], keep='last').reset_index(drop=True)\n",
    "    df_features = df_close_only[['asset', 'day']]     #a df that contains the new feature to reduce loading time in each function call.\n",
    "\n",
    "    #features not using intervals data\n",
    "    df_features = pd.merge(df_features, add_period(df_close_only), left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "    df_features = pd.merge(df_features, add_remainder(df_close_only), left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "    df_features = pd.merge(df_close_only, df_features, left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "\n",
    "    #ctc returns\n",
    "    ctc_features = pd.concat([ctc_returns(df_close_only[df_close_only['asset'] == i]) for i in range(54)]).reset_index(drop=True)\n",
    "    df_features = pd.merge(df_features, ctc_features, left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "\n",
    "    #moving volume\n",
    "    movv_features = pd.concat([daily_volume_moving_ratio(df[df['asset'] == i]) for i in range(54)]).reset_index(drop=True)\n",
    "    df_features = pd.merge(df_features, movv_features, left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "\n",
    "    #talib features: iterate over each asset together, then merge by [\"asset\", \"day\"]\n",
    "    talib_features = pd.concat([add_talib_features(df[df['asset'] == i]) for i in range(54)]).reset_index(drop=True)\n",
    "    df_features = pd.merge(df_features, talib_features, left_on=[\"asset\", \"day\"], right_on=[\"asset\", \"day\"])\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time_x</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>asset</th>\n",
       "      <th>day</th>\n",
       "      <th>interval</th>\n",
       "      <th>...</th>\n",
       "      <th>daily_volume_moving_ratio_10d</th>\n",
       "      <th>daily_volume_moving_ratio_20d</th>\n",
       "      <th>SAR</th>\n",
       "      <th>SAREXT</th>\n",
       "      <th>RSI</th>\n",
       "      <th>HT_DCPERIOD</th>\n",
       "      <th>HT_PHASOR_inphase</th>\n",
       "      <th>HT_PHASOR_quadrature</th>\n",
       "      <th>HT_SINE_sine</th>\n",
       "      <th>HT_SINE_leadsine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s0d1p50</td>\n",
       "      <td>24.3731</td>\n",
       "      <td>24.3852</td>\n",
       "      <td>24.3852</td>\n",
       "      <td>24.3731</td>\n",
       "      <td>170476.0</td>\n",
       "      <td>4.157520e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s1d1p50</td>\n",
       "      <td>16.1557</td>\n",
       "      <td>16.1314</td>\n",
       "      <td>16.2771</td>\n",
       "      <td>16.1071</td>\n",
       "      <td>70944.0</td>\n",
       "      <td>1.146780e+06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2d1p50</td>\n",
       "      <td>9.0307</td>\n",
       "      <td>9.0307</td>\n",
       "      <td>9.0307</td>\n",
       "      <td>9.0307</td>\n",
       "      <td>84204.0</td>\n",
       "      <td>7.603632e+05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3d1p50</td>\n",
       "      <td>9.1521</td>\n",
       "      <td>9.1763</td>\n",
       "      <td>9.1763</td>\n",
       "      <td>9.1521</td>\n",
       "      <td>228997.0</td>\n",
       "      <td>2.099301e+06</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s4d1p50</td>\n",
       "      <td>5.0494</td>\n",
       "      <td>5.0615</td>\n",
       "      <td>5.0615</td>\n",
       "      <td>5.0494</td>\n",
       "      <td>114443.0</td>\n",
       "      <td>5.790603e+05</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91687</th>\n",
       "      <td>s49d1698p50</td>\n",
       "      <td>27.6139</td>\n",
       "      <td>27.5168</td>\n",
       "      <td>27.6139</td>\n",
       "      <td>27.5168</td>\n",
       "      <td>763444.0</td>\n",
       "      <td>2.100876e+07</td>\n",
       "      <td>49</td>\n",
       "      <td>1698</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682980</td>\n",
       "      <td>0.454241</td>\n",
       "      <td>11.0699</td>\n",
       "      <td>11.0699</td>\n",
       "      <td>-10.992403</td>\n",
       "      <td>21.998470</td>\n",
       "      <td>-0.801573</td>\n",
       "      <td>0.356923</td>\n",
       "      <td>-0.959057</td>\n",
       "      <td>-0.477895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91688</th>\n",
       "      <td>s50d1698p50</td>\n",
       "      <td>28.8277</td>\n",
       "      <td>28.8642</td>\n",
       "      <td>28.8642</td>\n",
       "      <td>28.8277</td>\n",
       "      <td>129948.0</td>\n",
       "      <td>3.750945e+06</td>\n",
       "      <td>50</td>\n",
       "      <td>1698</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.640335</td>\n",
       "      <td>0.678836</td>\n",
       "      <td>7.3556</td>\n",
       "      <td>7.3556</td>\n",
       "      <td>-0.750675</td>\n",
       "      <td>25.147935</td>\n",
       "      <td>1.696683</td>\n",
       "      <td>-2.689594</td>\n",
       "      <td>0.969677</td>\n",
       "      <td>0.858474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91689</th>\n",
       "      <td>s51d1698p50</td>\n",
       "      <td>10.1110</td>\n",
       "      <td>10.0867</td>\n",
       "      <td>10.1110</td>\n",
       "      <td>10.0867</td>\n",
       "      <td>231000.0</td>\n",
       "      <td>2.330026e+06</td>\n",
       "      <td>51</td>\n",
       "      <td>1698</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556928</td>\n",
       "      <td>0.466114</td>\n",
       "      <td>2.9010</td>\n",
       "      <td>2.9010</td>\n",
       "      <td>-14.200377</td>\n",
       "      <td>21.026962</td>\n",
       "      <td>0.032812</td>\n",
       "      <td>-0.105423</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>0.939044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91690</th>\n",
       "      <td>s52d1698p50</td>\n",
       "      <td>70.9709</td>\n",
       "      <td>70.7645</td>\n",
       "      <td>70.9709</td>\n",
       "      <td>70.7645</td>\n",
       "      <td>133374.0</td>\n",
       "      <td>9.435887e+06</td>\n",
       "      <td>52</td>\n",
       "      <td>1698</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615270</td>\n",
       "      <td>0.680688</td>\n",
       "      <td>8.1567</td>\n",
       "      <td>8.1567</td>\n",
       "      <td>8.323664</td>\n",
       "      <td>24.073693</td>\n",
       "      <td>3.718971</td>\n",
       "      <td>-1.475908</td>\n",
       "      <td>0.256981</td>\n",
       "      <td>-0.501647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91691</th>\n",
       "      <td>s53d1698p50</td>\n",
       "      <td>16.0222</td>\n",
       "      <td>16.0100</td>\n",
       "      <td>16.0222</td>\n",
       "      <td>16.0100</td>\n",
       "      <td>60900.0</td>\n",
       "      <td>9.751536e+05</td>\n",
       "      <td>53</td>\n",
       "      <td>1698</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486373</td>\n",
       "      <td>0.771643</td>\n",
       "      <td>6.6031</td>\n",
       "      <td>6.6031</td>\n",
       "      <td>6.104652</td>\n",
       "      <td>20.645288</td>\n",
       "      <td>1.002442</td>\n",
       "      <td>-2.920823</td>\n",
       "      <td>0.138628</td>\n",
       "      <td>-0.602255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91692 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_time_x     open    close     high      low    volume  \\\n",
       "0          s0d1p50  24.3731  24.3852  24.3852  24.3731  170476.0   \n",
       "1          s1d1p50  16.1557  16.1314  16.2771  16.1071   70944.0   \n",
       "2          s2d1p50   9.0307   9.0307   9.0307   9.0307   84204.0   \n",
       "3          s3d1p50   9.1521   9.1763   9.1763   9.1521  228997.0   \n",
       "4          s4d1p50   5.0494   5.0615   5.0615   5.0494  114443.0   \n",
       "...            ...      ...      ...      ...      ...       ...   \n",
       "91687  s49d1698p50  27.6139  27.5168  27.6139  27.5168  763444.0   \n",
       "91688  s50d1698p50  28.8277  28.8642  28.8642  28.8277  129948.0   \n",
       "91689  s51d1698p50  10.1110  10.0867  10.1110  10.0867  231000.0   \n",
       "91690  s52d1698p50  70.9709  70.7645  70.9709  70.7645  133374.0   \n",
       "91691  s53d1698p50  16.0222  16.0100  16.0222  16.0100   60900.0   \n",
       "\n",
       "              money  asset   day  interval  ... daily_volume_moving_ratio_10d  \\\n",
       "0      4.157520e+06      0     1        50  ...                           NaN   \n",
       "1      1.146780e+06      1     1        50  ...                           NaN   \n",
       "2      7.603632e+05      2     1        50  ...                           NaN   \n",
       "3      2.099301e+06      3     1        50  ...                           NaN   \n",
       "4      5.790603e+05      4     1        50  ...                           NaN   \n",
       "...             ...    ...   ...       ...  ...                           ...   \n",
       "91687  2.100876e+07     49  1698        50  ...                      0.682980   \n",
       "91688  3.750945e+06     50  1698        50  ...                      0.640335   \n",
       "91689  2.330026e+06     51  1698        50  ...                      0.556928   \n",
       "91690  9.435887e+06     52  1698        50  ...                      0.615270   \n",
       "91691  9.751536e+05     53  1698        50  ...                      0.486373   \n",
       "\n",
       "       daily_volume_moving_ratio_20d      SAR   SAREXT        RSI  \\\n",
       "0                                NaN      NaN      NaN        NaN   \n",
       "1                                NaN      NaN      NaN        NaN   \n",
       "2                                NaN      NaN      NaN        NaN   \n",
       "3                                NaN      NaN      NaN        NaN   \n",
       "4                                NaN      NaN      NaN        NaN   \n",
       "...                              ...      ...      ...        ...   \n",
       "91687                       0.454241  11.0699  11.0699 -10.992403   \n",
       "91688                       0.678836   7.3556   7.3556  -0.750675   \n",
       "91689                       0.466114   2.9010   2.9010 -14.200377   \n",
       "91690                       0.680688   8.1567   8.1567   8.323664   \n",
       "91691                       0.771643   6.6031   6.6031   6.104652   \n",
       "\n",
       "       HT_DCPERIOD  HT_PHASOR_inphase  HT_PHASOR_quadrature HT_SINE_sine  \\\n",
       "0              NaN                NaN                   NaN          NaN   \n",
       "1              NaN                NaN                   NaN          NaN   \n",
       "2              NaN                NaN                   NaN          NaN   \n",
       "3              NaN                NaN                   NaN          NaN   \n",
       "4              NaN                NaN                   NaN          NaN   \n",
       "...            ...                ...                   ...          ...   \n",
       "91687    21.998470          -0.801573              0.356923    -0.959057   \n",
       "91688    25.147935           1.696683             -2.689594     0.969677   \n",
       "91689    21.026962           0.032812             -0.105423     0.420903   \n",
       "91690    24.073693           3.718971             -1.475908     0.256981   \n",
       "91691    20.645288           1.002442             -2.920823     0.138628   \n",
       "\n",
       "       HT_SINE_leadsine  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "91687         -0.477895  \n",
       "91688          0.858474  \n",
       "91689          0.939044  \n",
       "91690         -0.501647  \n",
       "91691         -0.602255  \n",
       "\n",
       "[91692 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = merge_columns(df_market, df_fund, df_return)\n",
    "df = add_features(df_temp)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Insights on Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m asset_to_check \u001b[39m=\u001b[39m \u001b[39m43\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df_temp \u001b[39m=\u001b[39m df[(df[\u001b[39m'\u001b[39m\u001b[39masset\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m asset_to_check) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m)][[\u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRSI\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m ax \u001b[39m=\u001b[39m df_temp[[\u001b[39m'\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mplot(figsize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m15\u001b[39m), color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m ax\u001b[39m.\u001b[39mset_xlabel(\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "asset_to_check = 43\n",
    "df_temp = df[(df['asset'] == asset_to_check) & (df['day'] <= 1000)][['close', 'RSI']]\n",
    "ax = df_temp[['close']].plot(figsize=(30, 15), color='red')\n",
    "ax.set_xlabel(\"time\")\n",
    "ax.set_ylabel(\"close price\")\n",
    "#ax2 is to construct a second y axis on the graph (ax object)\n",
    "ax2 = ax.twinx()\n",
    "df_temp[['RSI']].plot(ax=ax2, style=\"--\")\n",
    "ax2.set_ylabel(\"RSI\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it to the Model (Reusing Part1's XGBoost (replace with lightgbm later?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag(df, target_map):\n",
    "    for i in [700, 750, 800, 850, 900, 950]:   #needs to be larger than the 700 days in the future.\n",
    "        df[f'lag{i}'] = (df.index - i*54).map(target_map)       #since each asset row is distanted at 54 rows (by 53)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global returns_avg\n",
    "features2 = ['turnoverRatio',\n",
    "       'transactionAmount', 'pe_ttm', 'pe', 'pb', 'ps', 'pcf',\n",
    "       'remainder7', 'remainder14',\n",
    "       'ctc1', 'ctc5', 'ctc10',\n",
    "       'ctc20', 'daily_volume_moving_ratio_5d',\n",
    "       'daily_volume_moving_ratio_10d', 'daily_volume_moving_ratio_20d', 'SAR',\n",
    "       'SAREXT', 'RSI', 'HT_DCPERIOD', 'HT_PHASOR_inphase',\n",
    "       'HT_PHASOR_quadrature', 'HT_SINE_sine', 'HT_SINE_leadsine']\n",
    "TARGET = 'return'\n",
    "features2 = features2 + [f\"lag{i}\" for i in [700, 750, 800, 850, 900, 950]]\n",
    "FEATURES4 = ['pcf', 'pe', 'pb', 'pe_ttm', 'ps', 'transactionAmount', 'turnoverRatio', 'money', 'open', 'close', 'high', 'low'] + [f\"period{i}\" for i in range(2, 15)] + [f\"remainder{i}\" for i in range(2, 15)]\n",
    "FEATURES5 = FEATURES4 + [f\"lag{i}\" for i in [700, 750, 800, 850, 900, 950]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(df_train, df_test, asset_type, features):\n",
    "    # major changes to previous one: previous we have set arbitary where to split train and test set (e.g. 7:3)\n",
    "    # this version make uses tss to have multiple folds of train and test sets (*without information leakage)\n",
    "    lag_adjuster = df_train.shape[0]\n",
    "\n",
    "    df_train = df_train[df_train['asset'] == asset_type]\n",
    "    df_test = df_test[df_test['asset'] == asset_type]\n",
    "\n",
    "    train_map = df_train['return'].to_dict()\n",
    "    df_train = add_lag(df_train, train_map)\n",
    "    df_train['isFuture'] = False\n",
    "    df_test['isFuture'] = True\n",
    "    df_test.index += lag_adjuster\n",
    "    train_and_test = pd.concat([df_train, df_test])\n",
    "    tat_map = train_and_test['return'].to_dict()\n",
    "    train_and_test = add_lag(train_and_test, tat_map)\n",
    "    df_test = train_and_test[train_and_test['isFuture'] == True].copy()\n",
    "\n",
    "    x_all = df_train[features]\n",
    "    y_all = df_train[TARGET]\n",
    "\n",
    "    reg = xgb.XGBRegressor(n_estimators=2000,\n",
    "                    booster=\"gbtree\",\n",
    "                    objective=\"reg:linear\",\n",
    "                    max_depth=2,            #high value leads to overfitting\n",
    "                    learning_rate=0.4,\n",
    "                    min_child_weight=6,             #higher value prevent overfitting (1000:700 ratio makes it easy to overfit)\n",
    "                    subsample=1,\n",
    "                    )\n",
    "    \n",
    "    reg.fit(x_all, y_all,\n",
    "            eval_set=[(x_all, y_all)],\n",
    "            verbose=20)\n",
    "    \n",
    "    df_test['prediction'] = reg.predict(df_test[features])\n",
    "    df_progress = df_test[['prediction']]\n",
    "    #return df_progress\n",
    "    avg_adjusted_prediction = df_progress['prediction'] - (df_progress['prediction'].mean() - returns_avg[asset_type])\n",
    "    return avg_adjusted_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_all():\n",
    "    df_train = add_features(merge_columns(df_train_market, df_train_fund, df_train_returns))\n",
    "    df_test = add_features(merge_columns(df_market, df_fund))\n",
    "    global returns_avg\n",
    "    returns_avg = [df_train[df_train['asset'] == i]['return'].mean() for i in range(54)]\n",
    "\n",
    "    df_res = train_predict(df_train, df_test, 0, features_build)\n",
    "    for i in range(1, 54):\n",
    "        df_res = pd.concat((df_res, train_predict(df_train, df_test, i, features_build)))\n",
    "\n",
    "    df_copy = df_res.sort_index()\n",
    "    df_copy = df_copy.reset_index()\n",
    "    dt_col = df_fund['date_time']\n",
    "    df_copy['date_time'] = dt_col\n",
    "    df_copy = df_copy[['date_time', 'prediction']]\n",
    "    df_copy.columns = ['date_time', 'return']\n",
    "    return df_copy\n",
    "\n",
    "df_res = train_predict_all()\n",
    "df_res\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Hacking and Hyper Parameter Tuning 👎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2day_return = df_market[df_market['interval'] == 50]\n",
    "df_2day_return = df_2day_return.reset_index()\n",
    "df_2day_return = df_2day_return[['date_time', 'close']]\n",
    "close_map = df_2day_return['close'].to_dict()\n",
    "\n",
    "df_2day_return['close_2day_later'] = (df_2day_return.index + 2*54).map(close_map)\n",
    "df_2day_return['2day_return'] = (df_2day_return['close_2day_later'] - df_2day_return['close']) / df_2day_return['close']\n",
    "df_2day_return = df_2day_return.fillna(0)\n",
    "real_2day_returns = df_2day_return['2day_return']\n",
    "\n",
    "df_2day_return2 = df_2day_return.copy()\n",
    "df_2day_return2['close_2day_later'] = (df_2day_return2.index - 2*54).map(close_map)\n",
    "df_2day_return2['2day_return'] = (df_2day_return2['close_2day_later'] - df_2day_return2['close']) / df_2day_return2['close']\n",
    "df_2day_return2 = df_2day_return2.fillna(0)\n",
    "real_2day_returns2 = df_2day_return2['2day_return']\n",
    "\n",
    "real_2day_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_res['return'].corr(real_2day_returns)) #should be the correct one.\n",
    "print(df_res['return'].corr(real_2day_returns2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makeshift Analysis on the return of the investment\n",
    "\n",
    "A very basic computation of the average return among the asset chosen on each day, without catering transaction fees or closing fees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = add_date(df_res)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(1001, 1002):\n",
    "    return_list = df_test[df_test['day'] == d]['return']\n",
    "    returns_based_decision = return_list.apply(lambda x: 1 if x > 0.02 else 0)\n",
    "    # returns_based_decision = list(returns_based_decision)\n",
    "    print(f\"This is Day: {d}, Returns are:\")\n",
    "    returns_based_weighting = returns_based_decision / returns_based_decision.sum()\n",
    "    print(returns_based_weighting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
